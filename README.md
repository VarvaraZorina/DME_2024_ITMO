# Инжиниринг управления данными

## Анализ частоты и интенсивности погодных явлений, ведущих к экономическим потерям в различных регионах РФ

### Описание проекта
Данный проект направлен на анализ данных о погодных явлениях в России с целью выявления их влияния на экономические потери в различных федеральных округах. В проекте используются данные о погоде, которые позволяют оценить частоту и интенсивность различных явлений, а также выявить регионы и временные периоды, подверженные наибольшим рискам экономических убытков.

### Структура проекта
```
DME_2024_ITMO/
├── database/ 
│   ├── backup_file.backup      # Резервная копия базы данных PostgreSQL, созданная для восстановления данных при необходимости.
│   ├── db_connection.py        # Файл для подключения к базе данных PostgreSQL и выполнения SQL-запросов.
│   └── docker-compose.yml      # Конфигурационный файл для запуска контейнеров PostgreSQL и pgAdmin с помощью Docker.
├── images/                     # Папка с графиками, созданными в процессе анализа данных.
│   └── ...                     # Здесь могут находиться изображения графиков, созданных с использованием библиотек визуализации.
├── pages/                     
│   ├── fd.py                   # Streamlit-страница с дэшбордом по федеральным округам, где отображаются данные и графики.
│   └── regions.py              # Streamlit-страница с дэшбордом по регионам, предоставляющая визуализацию и анализ данных по регионам.
├── app.py                      # Основной файл приложения Streamlit, который объединяет все страницы и визуализации.
├── dataset_input.xlsx          # Исходный файл с данными о погодных явлениях в формате Excel.
├── dataset_output.csv          # Выходной файл с обработанными данными в формате CSV, полученными после анализа и очистки исходных данных.
├── dme_project.ipynb           # Jupyter Notebook с кодом обработки и анализа данных, где проводятся эксперименты и визуализации.
└── requirements.txt            # Файл с зависимостями проекта, необходимыми для установки через pip.
```
### Запуск проекта

Шаг 1: Установка необходимых зависимостей

Перед запуском проекта убедитесь, что у вас установлены все необходимые библиотеки. Вы можете установить их, используя файл `requirements.txt`, который содержит список всех зависимостей.

```bash
pip install -r requirements.txt
```

Шаг 2: Запуск контейнеров с базой данных

Проект использует Docker для управления базой данных PostgreSQL. Для запуска контейнеров выполните следующую команду в директории, где находится файл `docker-compose.yml`:

```bash
docker-compose up -d
```

Эта команда создаст и запустит контейнеры PostgreSQL и pgAdmin в фоновом режиме.

Шаг 3: Загрузка данных с помощью резервной копии

```bash
docker cp /path/to/dme_backup.sql postgres_db:/dme_backup.sql
```

После копирования файла выполните следующие команды внутри контейнера PostgreSQL для восстановления базы данных:

```bash
docker exec -it postgres_db pg_restore -U postgres -d pg_db /backup_file.backup
```

Шаг 4: Запуск приложения Streamlit

После завершения всех предыдущих шагов вы можете запустить приложение Streamlit. Для этого выполните следующую команду в директории проекта:

```bash
streamlit run app.py
```

Это откроет ваше приложение в браузере по адресу `http://localhost:8501`.


### Основные этапы работы
1. **Загрузка данных**: 
2. **Обработка данных**: 
   - Фильтрация и группировка данных по федеральным округам и годам.
   - Вычисление средней интенсивности и продолжительности погодных явлений.
   - Данные загружаются из файла `dataset_input.xlsx`.
   - Визуализация данных:
      - Построение графиков распределения погодных явлений по федеральным округам.
      - Анализ пар явлений, наблюдаемых одновременно.
   - Обработанные данные сохраняются в файл `dataset_output.csv`.
3. **Интеграция с базой данных PostgreSQL**: Данные загружены в базу данных для дальнейшего хранения и обработки.
4. **Подключение к дэшборду**: Streamlit дэшборды, которые отображают графики и визуализации на основе проанализированных данных.

